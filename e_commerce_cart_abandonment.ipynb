{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# E-Commerce Cart Abandonment Prediction\n",
    "\n",
    "- Name: **Fahrettin Ege Bilge**\n",
    "- ID: **21070001052**\n",
    "- Instructor: **Assoc. Prof. Dr. Ömer ÇETİN**\n",
    "\n",
    "## Table Of Contents\n",
    "\n",
    "1. [Introduction](#Introduction)\n",
    "2. [Preprocessing](#Preprocessing)\n",
    "    - [Overview of Preprocessing Steps](#Overview-of-Preprocessing-Steps)\n",
    "3. [Split Dataset](#Split-Dataset)\n",
    "4. [Machine Learning Algorithm Selection](#Machine-Learning-Algorithm-Selection)\n",
    "    - [1. Logistic Regression: A baseline algorithm for binary classification.](#1.-Logistic-Regression:-A-baseline-algorithm-for-binary-classification.)\n",
    "    - [2.K-Nearest Neighbors (KNN): A distance-based classification model.](#2.K-Nearest-Neighbors-(KNN):-A-distance-based-classification-model.)\n",
    "    - [3. Support Vector Machines (SVM): Clear decision boundary for classification tasks.](#3.-Support-Vector-Machines-(SVM):-Clear-decision-boundary-for-classification-tasks.)\n",
    "    - [4. Naive Bayes: Complements one-hot encoding.](#4.-Naive-Bayes:-Complements-one-hot-encoding.)\n",
    "5. [Evaluation Metrics](#Evaluation-Metrics)\n",
    "    - [Accuracy](#Accuracy)\n",
    "    - [Precision](#Precision)\n",
    "    - [Recall](#Recall)\n",
    "    - [F1-Score](#F1-Score)\n",
    "    - [Confusion Matrix](#Confusion-Matrix)\n",
    "\n",
    "## Introduction\n",
    "Predicting cart abandonment is crucial for e-commerce platforms to reduce lost revenue and improve user experience. This project uses supervised learning techniques to predict the likelihood of users abandoning their carts based on features like cart contents, payment methods, and purchase history."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "### Overview of Preprocessing Steps\n",
    "1. Filtering Relevant Rows:\n",
    "- Rows with status values other than canceled and complete were removed.\n",
    "- Justification: canceled maps to abandoned = 1, while complete maps to abandoned = 0. Other statuses do not provide relevant information for this task.\n",
    "2. Handling Categorical Features:\n",
    "- Categorical variables (category_name_1 and payment_method) were one-hot encoded.\n",
    "- Justification: One-hot encoding ensures that these variables are represented in a format suitable for machine learning models without assuming any ordinal relationship.\n",
    "3. Handling Numerical Features:\n",
    "- Numerical features (price, grand_total, discount_amount, total_purchases, and total_orders) were scaled using MinMaxScaler.\n",
    "- Justification: Scaling ensures that all features are normalized, preventing features with large magnitudes from dominating the model.\n",
    "4. Outlier Handling:\n",
    "- Numerical columns were clipped at the 95th percentile to mitigate the effect of outliers.\n",
    "- Justification: Outliers can disproportionately influence certain machine learning models like Logistic Regression or KNN.\n",
    "5. Tracking Customer History:\n",
    "- Aggregated total_purchases (sum of grand_total for each customer) and total_orders (number of orders per customer) were added as features.\n",
    "- Justification: These features provide insights into customer behavior and engagement, which are critical for predicting cart abandonment.\n",
    "6. Balancing the Dataset:\n",
    "- Undersampling was used to balance the dataset by ensuring equal representation of abandoned (1) and not abandoned (0) classes.\n",
    "- Justification: An imbalanced dataset can bias the model towards the majority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/egebilge/Developer/GitHub/E-commerce-Cart-Abandonment-Prediction/helper.py:6: DtypeWarning: Columns (1,2,3,7,8,9,11,12,13,14,17,18,19) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(input_file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed dataset saved to data/preprocessed_dataset/preprocessed_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "import helper as hlp\n",
    "kaggle_dataset = 'data/kaggle_dataset/Pakistan_Largest_Ecommerce_Dataset.csv'\n",
    "preprocessed_dataset = 'data/preprocessed_dataset/preprocessed_dataset.csv'\n",
    "hlp.preprocess_dataset(kaggle_dataset, preprocessed_dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Algorithm Selection\n",
    "Justification for Algorithm Choices\n",
    "\n",
    "1. Logistic Regression:\n",
    "- Chosen for its simplicity, interpretability, and efficiency on linearly separable data.\n",
    "- It also provides probabilities for predictions, making it suitable for understanding the likelihood of cart abandonment.\n",
    "2. K-Nearest Neighbors (KNN):\n",
    "- A non-parametric algorithm that uses similarity measures to make predictions.\n",
    "- Effective for capturing local patterns and relationships in the data.\n",
    "3. Support Vector Machines (SVM):\n",
    "- Robust to high-dimensional spaces and outliers, making it a good choice for scaled numerical features.\n",
    "- Provides a clear decision boundary for classification tasks.\n",
    "4. Naive Bayes:\n",
    "- Efficient and works well for categorical data due to its assumption of feature independence.\n",
    "- It complements the one-hot encoded categorical features in our dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Logistic Regression: A baseline algorithm for binary classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.K-Nearest Neighbors (KNN): A distance-based classification model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Support Vector Machines (SVM): Clear decision boundary for classification tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Naive Bayes: Complements one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Metrics\n",
    "\n",
    "- **Accuracy**: Overall correctness of predictions.\n",
    "- **Precision**: Ratio of true positive predictions to all positive predictions.\n",
    "- **Recall**: Ratio of true positives to all actual positives.\n",
    "- **F1 Score**: Harmonic mean of precision and recall.\n",
    "- **Confusion Matrix**: Visualization of classification performance.\n",
    "\n",
    "#### Accuracy\n",
    "$$\n",
    "\\text{Accuracy} = \\frac{\\text{TP} + \\text{TN}}{\\text{TP} + \\text{TN} + \\text{FP} + \\text{FN}}\n",
    "$$\n",
    "\n",
    "#### Precision\n",
    "$$\n",
    "\\text{Precision} = \\frac{\\text{TP}}{\\text{TP} + \\text{FP}}\n",
    "$$\n",
    "\n",
    "#### Recall\n",
    "$$\n",
    "\\text{Recall} = \\frac{\\text{TP}}{\\text{TP} + \\text{FN}}\n",
    "$$\n",
    "\n",
    "#### F1-Score\n",
    "$$\n",
    "F_1 = 2 \\cdot \\frac{\\text{Precision} \\cdot \\text{Recall}}{\\text{Precision} + \\text{Recall}}\n",
    "$$\n",
    "\n",
    "#### Confusion Matrix\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "\\text{TP} & \\text{FP} \\\\\n",
    "\\text{FN} & \\text{TN}\n",
    "\\end{bmatrix}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "- Comparison of model performance on test data.\n",
    "- Discussion of strengths and weaknesses of each algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "Summarize findings, highlight key insights, and suggest potential improvements for future work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendices\n",
    "- Sample code snippets.\n",
    "## References\n",
    "- Dataset: https://www.kaggle.com/datasets/zusmani/pakistans-largest-ecommerce-dataset/data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
