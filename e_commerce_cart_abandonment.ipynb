{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# E-Commerce Cart Abandonment Prediction\n",
    "\n",
    "- Name: **Fahrettin Ege Bilge**\n",
    "- ID: **21070001052**\n",
    "- Instructor: **Assoc. Prof. Dr. Ömer ÇETİN**\n",
    "\n",
    "## Table Of Contents\n",
    "\n",
    "1. [Introduction](#Introduction)\n",
    "2. [Preprocessing](#Preprocessing)\n",
    "    - [Overview of Preprocessing Steps](#Overview-of-Preprocessing-Steps)\n",
    "3. [Split Dataset](#Split-Dataset)\n",
    "4. [Machine Learning Algorithm Selection](#Machine-Learning-Algorithm-Selection)\n",
    "    - [1. Logistic Regression: A baseline algorithm for binary classification.](#1.-Logistic-Regression:-A-baseline-algorithm-for-binary-classification.)\n",
    "    - [2.K-Nearest Neighbors (KNN): A distance-based classification model.](#2.K-Nearest-Neighbors-(KNN):-A-distance-based-classification-model.)\n",
    "    - [3. Support Vector Machines (SVM): Clear decision boundary for classification tasks.](#3.-Support-Vector-Machines-(SVM):-Clear-decision-boundary-for-classification-tasks.)\n",
    "    - [4. Naive Bayes: Complements one-hot encoding.](#4.-Naive-Bayes:-Complements-one-hot-encoding.)\n",
    "5. [Evaluation Metrics](#Evaluation-Metrics)\n",
    "    - [Accuracy](#Accuracy)\n",
    "    - [Precision](#Precision)\n",
    "    - [Recall](#Recall)\n",
    "    - [F1-Score](#F1-Score)\n",
    "    - [Confusion Matrix](#Confusion-Matrix)\n",
    "6. [Results](#Results)\n",
    "7. [Conclusion](#Conclusion)\n",
    "8. [Appendices](#Appendices)\n",
    "9. [References](#References)\n",
    "\n",
    "\n",
    "## Introduction\n",
    "Predicting cart abandonment is crucial for e-commerce platforms to reduce lost revenue and improve user experience. This project uses supervised learning techniques to predict the likelihood of users abandoning their carts based on features like cart contents, payment methods, and purchase history."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "### Overview of Preprocessing Steps\n",
    "1. Filtering Relevant Rows:\n",
    "- Rows with status values other than canceled and complete were removed.\n",
    "- Justification: canceled maps to abandoned = 1, while complete maps to abandoned = 0. Other statuses do not provide relevant information for this task.\n",
    "2. Handling Categorical Features:\n",
    "- Categorical variables (category_name_1 and payment_method) were one-hot encoded.\n",
    "- Justification: One-hot encoding ensures that these variables are represented in a format suitable for machine learning models without assuming any ordinal relationship.\n",
    "3. Handling Numerical Features:\n",
    "- Numerical features (price, grand_total, discount_amount, total_purchases, and total_orders) were scaled using MinMaxScaler.\n",
    "- Justification: Scaling ensures that all features are normalized, preventing features with large magnitudes from dominating the model.\n",
    "4. Outlier Handling:\n",
    "- Numerical columns were clipped at the 95th percentile to mitigate the effect of outliers.\n",
    "- Justification: Outliers can disproportionately influence certain machine learning models like Logistic Regression or KNN.\n",
    "5. Tracking Customer History:\n",
    "- Aggregated total_purchases (sum of grand_total for each customer) and total_orders (number of orders per customer) were added as features.\n",
    "- Justification: These features provide insights into customer behavior and engagement, which are critical for predicting cart abandonment.\n",
    "6. Balancing the Dataset:\n",
    "- Undersampling was used to balance the dataset by ensuring equal representation of abandoned (1) and not abandoned (0) classes.\n",
    "- Justification: An imbalanced dataset can bias the model towards the majority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/egebilge/Developer/GitHub/E-commerce-Cart-Abandonment-Prediction/helper.py:6: DtypeWarning: Columns (1,2,3,7,8,9,11,12,13,14,17,18,19) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(input_file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed dataset saved to data/preprocessed_dataset/preprocessed_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "import helper as hlp\n",
    "kaggle_dataset = 'data/kaggle_dataset/Pakistan_Largest_Ecommerce_Dataset.csv'\n",
    "preprocessed_dataset = 'data/preprocessed_dataset/preprocessed_dataset.csv'\n",
    "hlp.preprocess_dataset(kaggle_dataset, preprocessed_dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Dataset\n",
    "To train and evaluate machine learning models effectively, the dataset is split into training and testing subsets. This ensures that the model is trained on one portion of the data and evaluated on unseen data to measure its performance. \n",
    "\n",
    "#### Steps:\n",
    "1. **Train-Test Split**: \n",
    "   - The dataset is split into 80% training data and 20% testing data.\n",
    "2. **Stratification**: \n",
    "   - Stratified splitting ensures that the class distribution (abandoned vs. not abandoned) is preserved in both the training and testing datasets.\n",
    "3. **Random State**: \n",
    "   - Setting a `random_state` ensures reproducibility of results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Split Information:\n",
      "Training data shape: (321998, 43) (Features), (321998,) (Target)\n",
      "Testing data shape: (80500, 43) (Features), (80500,) (Target)\n",
      "\n",
      "Class Distribution in Training Data:\n",
      "  Class 1.0: 50.00%\n",
      "  Class 0.0: 50.00%\n",
      "\n",
      "Class Distribution in Testing Data:\n",
      "  Class 0.0: 50.00%\n",
      "  Class 1.0: 50.00%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define features (X) and target variable (y)\n",
    "X = df.drop(columns=['abandoned'])  # Features\n",
    "y = df['abandoned']                # Target variable\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2,          # 20% of the data for testing\n",
    "    stratify=y,             # Preserve class distribution\n",
    "    random_state=42         # Ensure reproducibility\n",
    ")\n",
    "\n",
    "# Display shapes and class distribution\n",
    "print(\"Dataset Split Information:\")\n",
    "print(f\"Training data shape: {X_train.shape} (Features), {y_train.shape} (Target)\")\n",
    "print(f\"Testing data shape: {X_test.shape} (Features), {y_test.shape} (Target)\")\n",
    "\n",
    "# Display class distribution in training and testing sets\n",
    "train_class_distribution = y_train.value_counts(normalize=True).to_dict()\n",
    "test_class_distribution = y_test.value_counts(normalize=True).to_dict()\n",
    "\n",
    "print(\"\\nClass Distribution in Training Data:\")\n",
    "for class_label, proportion in train_class_distribution.items():\n",
    "    print(f\"  Class {class_label}: {proportion:.2%}\")\n",
    "\n",
    "print(\"\\nClass Distribution in Testing Data:\")\n",
    "for class_label, proportion in test_class_distribution.items():\n",
    "    print(f\"  Class {class_label}: {proportion:.2%}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Algorithm Selection\n",
    "Justification for Algorithm Choices\n",
    "\n",
    "1. Logistic Regression:\n",
    "- Chosen for its simplicity, interpretability, and efficiency on linearly separable data.\n",
    "- It also provides probabilities for predictions, making it suitable for understanding the likelihood of cart abandonment.\n",
    "2. K-Nearest Neighbors (KNN):\n",
    "- A non-parametric algorithm that uses similarity measures to make predictions.\n",
    "- Effective for capturing local patterns and relationships in the data.\n",
    "3. Support Vector Machines (SVM):\n",
    "- Robust to high-dimensional spaces and outliers, making it a good choice for scaled numerical features.\n",
    "- Provides a clear decision boundary for classification tasks.\n",
    "4. Naive Bayes:\n",
    "- Efficient and works well for categorical data due to its assumption of feature independence.\n",
    "- It complements the one-hot encoded categorical features in our dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Logistic Regression: A baseline algorithm for binary classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.K-Nearest Neighbors (KNN): A distance-based classification model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Support Vector Machines (SVM): Clear decision boundary for classification tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Naive Bayes: Complements one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Metrics\n",
    "\n",
    "- **Accuracy**: Overall correctness of predictions.\n",
    "- **Precision**: Ratio of true positive predictions to all positive predictions.\n",
    "- **Recall**: Ratio of true positives to all actual positives.\n",
    "- **F1 Score**: Harmonic mean of precision and recall.\n",
    "- **Confusion Matrix**: Visualization of classification performance.\n",
    "\n",
    "#### Accuracy\n",
    "$$\n",
    "\\text{Accuracy} = \\frac{\\text{TP} + \\text{TN}}{\\text{TP} + \\text{TN} + \\text{FP} + \\text{FN}}\n",
    "$$\n",
    "\n",
    "#### Precision\n",
    "$$\n",
    "\\text{Precision} = \\frac{\\text{TP}}{\\text{TP} + \\text{FP}}\n",
    "$$\n",
    "\n",
    "#### Recall\n",
    "$$\n",
    "\\text{Recall} = \\frac{\\text{TP}}{\\text{TP} + \\text{FN}}\n",
    "$$\n",
    "\n",
    "#### F1-Score\n",
    "$$\n",
    "F_1 = 2 \\cdot \\frac{\\text{Precision} \\cdot \\text{Recall}}{\\text{Precision} + \\text{Recall}}\n",
    "$$\n",
    "\n",
    "#### Confusion Matrix\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "\\text{TP} & \\text{FP} \\\\\n",
    "\\text{FN} & \\text{TN}\n",
    "\\end{bmatrix}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "- Comparison of model performance on test data.\n",
    "- Discussion of strengths and weaknesses of each algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "Summarize findings, highlight key insights, and suggest potential improvements for future work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendices\n",
    "- Sample code snippets.\n",
    "## References\n",
    "- Dataset: https://www.kaggle.com/datasets/zusmani/pakistans-largest-ecommerce-dataset/data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
